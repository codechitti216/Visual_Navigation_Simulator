#!/usr/bin/env python3
"""
Create ViNT inference video from TORCS trajectory data
Runs REAL ViNT inference on all frames with proper sliding window
"""

import os
import pandas as pd
import numpy as np
from PIL import Image as PILImage
import matplotlib.pyplot as plt
import sys
import torch
import yaml
import cv2
from tqdm import tqdm
import subprocess

# Add ViNT paths  
sys.path.append("visualnav-transformer/train")
import torch.nn as nn
from torchvision import transforms
import torchvision.transforms.functional as TF

class TORCSVideoGenerator:
    def __init__(self, data_dir="vint_torcs_logs"):
        # Find the latest session directory
        self.data_dir = self.find_latest_session(data_dir)
        print(f"Using data from: {self.data_dir}")
        
        # Load TORCS data
        self.load_torcs_data()
        
        # Load REAL ViNT model
        self.load_vint_model()
        
        # Video settings
        self.video_fps = 10  # 10 FPS for smooth playback
        self.video_width = 1920  # Full HD width
        self.video_height = 800   # Height to match our visualization
        
    def find_latest_session(self, base_dir):
        """Find the most recent session directory"""
        if not os.path.exists(base_dir):
            raise FileNotFoundError(f"Data directory not found: {base_dir}")
        
        sessions = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]
        if not sessions:
            raise FileNotFoundError(f"No session directories found in {base_dir}")
        
        latest_session = sorted(sessions)[-1]
        return os.path.join(base_dir, latest_session)
    
    def load_torcs_data(self):
        """Load TORCS trajectory data"""
        # Load pose data
        pose_file = os.path.join(self.data_dir, "pose.csv") 
        if not os.path.exists(pose_file):
            raise FileNotFoundError(f"Pose file not found: {pose_file}")
        
        self.pose_data = pd.read_csv(pose_file)
        print(f"Loaded {len(self.pose_data)} pose records")
        
        # Load frames
        frames_dir = os.path.join(self.data_dir, "frames")
        self.frame_paths = sorted([
            os.path.join(frames_dir, f) for f in os.listdir(frames_dir) 
            if f.endswith('.png')
        ])
        
        # Load goal image (last frame)
        self.goal_image = PILImage.open(self.frame_paths[-1])
        
        print(f"Loaded {len(self.frame_paths)} frames")
        print(f"Goal image: {self.frame_paths[-1]}")
        
    def load_vint_model(self):
        """Load the REAL ViNT model from vint.pth"""
        print("Loading REAL ViNT model from vint.pth...")
        
        # Setup device
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {self.device}")
        
        # Load model config
        try:
            model_config_path = "visualnav-transformer/train/config/vint.yaml"
            with open(model_config_path, "r") as f:
                self.model_params = yaml.safe_load(f)
                print(f"‚úì Loaded model config from {model_config_path}")
        except Exception as e:
            print(f"Using default config: {e}")
            self.model_params = {
                'context_size': 5,
                'len_traj_pred': 5,
                'image_size': [224, 224],
                'normalize': True,
                'learn_angle': True,
                'obs_encoder': 'vit',
                'obs_encoding_size': 512,
                'late_fusion': False,
                'mha_num_attention_heads': 8,
                'mha_num_attention_layers': 4,
                'mha_ff_dim_factor': 4,
            }
        
        # Load REAL ViNT model
        try:
            from vint_train.models.vint.vint import ViNT
            
            self.model = ViNT(
                context_size=self.model_params["context_size"],
                len_traj_pred=self.model_params["len_traj_pred"],
                learn_angle=self.model_params["learn_angle"],
                obs_encoder=self.model_params["obs_encoder"],
                obs_encoding_size=self.model_params["obs_encoding_size"],
                late_fusion=self.model_params["late_fusion"],
                mha_num_attention_heads=self.model_params["mha_num_attention_heads"],
                mha_num_attention_layers=self.model_params["mha_num_attention_layers"],
                mha_ff_dim_factor=self.model_params["mha_ff_dim_factor"],
            )
            
            # Load weights from vint.pth
            model_weights_path = "vint.pth"
            print(f"Loading model weights from {model_weights_path}...")
            
            checkpoint = torch.load(model_weights_path, map_location=self.device, weights_only=False)
            
            # Extract model state dict
            if 'model' in checkpoint:
                loaded_model = checkpoint["model"]
                if hasattr(loaded_model, 'module'):
                    state_dict = loaded_model.module.state_dict()
                else:
                    state_dict = loaded_model.state_dict()
            else:
                state_dict = checkpoint
                
            self.model.load_state_dict(state_dict, strict=False)
            self.model.to(self.device)
            self.model.eval()
            
            print(f"‚úì REAL ViNT model loaded successfully from vint.pth (411MB)")
            self.use_real_model = True
            
        except Exception as e:
            print(f"‚ùå Failed to load real ViNT model: {e}")
            print("Using dummy waypoints instead...")
            self.model = None
            self.use_real_model = False
            
        # Setup image transform
        self.transform = transforms.Compose([
            transforms.Resize(self.model_params['image_size']),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])
        
        print(f"‚úì Context size: {self.model_params['context_size']} frames")
        print(f"‚úì Trajectory prediction length: {self.model_params['len_traj_pred']} waypoints")

    def generate_dummy_waypoints(self, frame_idx):
        """Fallback dummy waypoints if real model fails"""
        np.random.seed(frame_idx)  # Consistent results
        waypoints = []
        for i in range(5):
            dx = 0.1 + i * 0.05 + np.random.normal(0, 0.02)
            dy = np.sin(frame_idx * 0.1 + i) * 0.05 + np.random.normal(0, 0.01)
            waypoints.append([dx, dy])
        return np.array(waypoints)

    def load_frame_sequence(self, current_idx, context_size=5):
        """Load REAL sliding window context frames (5 past + 1 current = 6 frames)"""
        frames = []
        start_idx = max(0, current_idx - context_size)
        
        for i in range(start_idx, current_idx + 1):
            if i < len(self.frame_paths):
                img = PILImage.open(self.frame_paths[i])
                frames.append(img)
        
        # Ensure we have exactly context_size + 1 frames (5 past + 1 current)
        while len(frames) < context_size + 1:
            frames.insert(0, frames[0])  # Pad with first frame
            
        return frames

    def transform_images_for_vint(self, pil_imgs):
        """Transform PIL images to tensor format for REAL ViNT model"""
        if not isinstance(pil_imgs, list):
            pil_imgs = [pil_imgs]
            
        # Transform each image
        tensors = []
        for pil_img in pil_imgs:
            tensor = self.transform(pil_img)
            tensors.append(tensor)
        
        # Stack along batch dimension
        return torch.stack(tensors, dim=0)

    def predict_waypoints_vint(self, current_idx):
        """Run REAL ViNT inference to predict waypoints"""
        if not self.use_real_model or self.model is None:
            print(f"  Frame {current_idx}: Using dummy waypoints (real model not available)")
            waypoints = self.generate_dummy_waypoints(current_idx)
            distance = 5.0
            return waypoints, distance
            
        # Load REAL context frames (5 past + 1 current = 6 frames sliding window)
        context_frames = self.load_frame_sequence(current_idx, self.model_params['context_size'])
        
        with torch.no_grad():
            # Transform REAL context images for ViNT
            obs_images = self.transform_images_for_vint(context_frames)
            goal_tensor = self.transform_images_for_vint([self.goal_image])
            
            # Move to device
            obs_images = obs_images.to(self.device).unsqueeze(0)  # Add batch dim
            goal_tensor = goal_tensor.to(self.device)
            
            # Run REAL ViNT inference
            dist_pred, action_pred = self.model(obs_images, goal_tensor)
            
            # Convert to numpy waypoints
            waypoints = action_pred.cpu().numpy().squeeze()  # Shape: (5, 2) or (5, 3)
            distance = dist_pred.cpu().numpy().squeeze()
            
            # Extract just x, y coordinates (ignore angle if present)
            if len(waypoints.shape) > 1 and waypoints.shape[-1] > 2:
                waypoints = waypoints[:, :2]
                
            print(f"  Frame {current_idx}: REAL ViNT prediction - {waypoints.shape[0]} waypoints")
                
        return waypoints, distance

    def create_frame_visualization(self, frame_idx, waypoints, distance=None):
        """Create visualization for a single frame"""
        # Load current frame
        current_img = PILImage.open(self.frame_paths[frame_idx])
        
        # Create figure with custom layout
        fig = plt.figure(figsize=(20, 8))
        
        # Main plot: Current observation with waypoints
        ax_main = plt.subplot2grid((3, 10), (0, 0), colspan=4, rowspan=3)
        ax_main.imshow(current_img)
        
        # Project waypoints onto image
        for i, (dx, dy) in enumerate(waypoints):
            # Simple projection: scale deltas to image coordinates
            x = current_img.width / 2 + dx * 80  
            y = current_img.height / 2 - dy * 80  
            
            # Clamp to image bounds
            x = max(20, min(current_img.width - 20, x))
            y = max(20, min(current_img.height - 20, y))
            
            # Color code waypoints (near to far: red to blue)
            colors = ['red', 'orange', 'yellow', 'lightgreen', 'blue']
            color = colors[i % len(colors)]
            
            ax_main.plot(x, y, 'o', color=color, markersize=12, markeredgecolor='white', markeredgewidth=2)
            ax_main.text(x + 10, y - 10, f't+{i+1}', color='white', fontweight='bold', fontsize=14,
                        bbox=dict(boxstyle="round,pad=0.3", facecolor=color, alpha=0.8))
        
        title_text = f'Frame {frame_idx}: {"REAL ViNT" if self.use_real_model else "Dummy"} Navigation Prediction'
        ax_main.set_title(title_text, fontsize=16, fontweight='bold')
        ax_main.axis('off')
        
        # Past 5 frames (sliding window context)
        past_frames = self.load_frame_sequence(frame_idx, 5)
        for i in range(min(5, len(past_frames) - 1)):  # Exclude current frame
            ax_past = plt.subplot2grid((3, 10), (i * 3 // 5, 5 + i), colspan=1, rowspan=1)
            ax_past.imshow(past_frames[i])
            ax_past.set_title(f't-{5-i}', fontsize=12, fontweight='bold')
            ax_past.axis('off')
        
        # Goal image
        ax_goal = plt.subplot2grid((3, 10), (1, 8), colspan=2, rowspan=2)
        ax_goal.imshow(self.goal_image)
        ax_goal.set_title('Goal Frame', fontsize=16, fontweight='bold')
        ax_goal.axis('off')
        
        # Add text information
        model_info = "REAL ViNT Model (vint.pth)" if self.use_real_model else "Dummy Waypoints"
        info_text = f"""Frame: {frame_idx}/{len(self.frame_paths)-1}
Model: {model_info}
Predicted Waypoints:
"""
        for i, (dx, dy) in enumerate(waypoints):
            info_text += f"  t+{i+1}: dx={dx:.3f}, dy={dy:.3f}\n"
            
        if distance is not None:
            info_text += f"\nPredicted Distance: {distance:.2f}\n"
            
        # Add ground truth info
        if frame_idx < len(self.pose_data):
            pose = self.pose_data.iloc[frame_idx]
            info_text += f"\nGround Truth:\n"
            info_text += f"  Position: ({pose['x']:.1f}, {pose['y']:.1f})\n"
            info_text += f"  Speed: {pose['speed']:.1f} m/s\n"
            info_text += f"  Heading: {pose['theta']:.2f} rad"
        
        plt.figtext(0.02, 0.02, info_text, fontsize=10, fontfamily='monospace',
                   bbox=dict(boxstyle="round,pad=0.5", facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        
        # Save frame to temporary file
        temp_path = f"temp_frame_{frame_idx:04d}.png"
        plt.savefig(temp_path, dpi=100, bbox_inches='tight', facecolor='white')
        plt.close()
        
        return temp_path

    def generate_video(self, start_frame=5, end_frame=None, output_name="vint_torcs_navigation.mp4"):
        """Generate video from ALL frames with real ViNT inference"""
        if end_frame is None:
            # Process ALL frames from 6 to final (as you requested)
            end_frame = len(self.frame_paths) - 1
            
        print(f"\nGenerating REAL ViNT Navigation Video:")
        print(f"- Start frame: {start_frame} (6th frame, 0-indexed)")
        print(f"- End frame: {end_frame} (final frame)")
        print(f"- Total frames: {end_frame - start_frame + 1}")
        print(f"- Using REAL ViNT model: {self.use_real_model}")
        print(f"- Sliding window: {self.model_params['context_size']} past + 1 current = 6 frames")
        print(f"- Video FPS: {self.video_fps}")
        print(f"- Output: {output_name}")
        
        # Generate all frame visualizations
        temp_files = []
        print("\nProcessing ALL frames with REAL ViNT inference...")
        
        for frame_idx in tqdm(range(start_frame, end_frame + 1), desc="REAL ViNT inference"):
            try:
                # Run REAL ViNT inference with sliding window
                waypoints, distance = self.predict_waypoints_vint(frame_idx)
                
                # Create visualization
                temp_path = self.create_frame_visualization(frame_idx, waypoints, distance)
                temp_files.append(temp_path)
                
            except Exception as e:
                print(f"Error processing frame {frame_idx}: {e}")
                continue
        
        if not temp_files:
            print("No frames were generated successfully!")
            return None
        
        print(f"\nCreating video from {len(temp_files)} frames...")
        
        # Create video using OpenCV
        first_frame = cv2.imread(temp_files[0])
        height, width, layers = first_frame.shape
        
        # Define codec and create VideoWriter
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = cv2.VideoWriter(output_name, fourcc, self.video_fps, (width, height))
        
        # Add all frames to video
        for temp_file in tqdm(temp_files, desc="Writing video"):
            frame = cv2.imread(temp_file)
            video_writer.write(frame)
        
        video_writer.release()
        
        # Clean up temporary files
        print("Cleaning up temporary files...")
        for temp_file in temp_files:
            try:
                os.remove(temp_file)
            except:
                pass
        
        print(f"‚úì Video saved as: {output_name}")
        return output_name

def main():
    print("TORCS REAL ViNT Navigation Video Generator")
    print("=" * 50)
    
    # Initialize video generator with REAL ViNT model
    generator = TORCSVideoGenerator()
    
    # Generate video with ALL frames (as you requested)
    video_file = generator.generate_video(
        start_frame=5,      # Start from 6th frame (0-indexed) 
        end_frame=None,     # Process ALL frames to final
        output_name="vint_torcs_navigation_REAL.mp4"
    )
    
    if video_file:
        print(f"\nüé¨ REAL ViNT Video generation complete!")
        print(f"üìÅ Video saved as: {video_file}")
        print(f"üé• This video shows REAL ViNT model predictions on your TORCS data!")
        print(f"‚úì 6-frame sliding window (5 past + 1 current)")
        print(f"‚úì REAL ViNT model inference using vint.pth (411MB)")
        print(f"‚úì Processed ALL frames from 6 to final")
        print(f"‚úì Proper sliding window context for each prediction")
        
        # Try to play the video
        print(f"\nAttempting to open video...")
        try:
            subprocess.run(["xdg-open", video_file], check=True)
            print("‚úì Video opened successfully!")
        except:
            print(f"Please manually open: {video_file}")
    else:
        print("‚ùå Video generation failed!")

if __name__ == "__main__":
    main() 